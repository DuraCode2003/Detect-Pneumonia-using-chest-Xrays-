{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DuraCode2003/Detect-Pneumonia-using-chest-Xrays-/blob/main/Untitled3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0xmC2q0_PACa",
        "outputId": "04801c00-1176-4dbd-8177-9c386360504d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.17.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.13.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.1.21)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.25.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.70.0)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.17.1)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.5.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.55.6)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (23.2.1)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.115.7)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.5.0)\n",
            "Requirement already satisfied: gradio-client==1.6.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.6.0)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.25.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.27.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.5)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.15)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.6)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.2.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.9.3)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.45.3)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.2)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.1)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.34.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.6.0->gradio) (2024.10.0)\n",
            "Requirement already satisfied: websockets<15.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.6.0->gradio) (14.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.1->gradio) (3.17.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->tensorflow) (0.14.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow opencv-python matplotlib gradio\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2dDLAopPY3I"
      },
      "source": [
        "import dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "F4sNYrEJPi8D",
        "outputId": "dd5c97f3-060f-43a7-bd26-19c7612f6234"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-7ffbd7c5-34bd-436d-96bf-38f539fd4b44\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-7ffbd7c5-34bd-436d-96bf-38f539fd4b44\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle (2).json\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'kaggle (2).json': b'{\"username\":\"durankakalpana\",\"key\":\"79ce5096d272571d6c6e15483da27c75\"}'}"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bAW8-tGuQtRw",
        "outputId": "0ce2dc74-6d5c-4112-be83-859eef8858c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /content/kaggle.json'\n",
            "Dataset URL: https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia\n",
            "License(s): other\n",
            "chest-xray-pneumonia.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ],
      "source": [
        "!pip install -q kaggle\n",
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content\"\n",
        "!kaggle datasets download -d paultimothymooney/chest-xray-pneumonia"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_WIQc6GRUKO"
      },
      "source": [
        "preprocessing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sHtuCF8JRXPp"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "import zipfile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z75KZR6XRzxF"
      },
      "outputs": [],
      "source": [
        "def preprocess_image(image):\n",
        "    image = cv2.resize(image, (224, 224))\n",
        "    image = image.astype('float32') / 255.0\n",
        "    return image\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KVuobpv9U0X0"
      },
      "outputs": [],
      "source": [
        "datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2, horizontal_flip=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZAH-lsjqUOS2"
      },
      "outputs": [],
      "source": [
        "with zipfile.ZipFile('/content/chest-xray-pneumonia.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/chest-xray-pneumonia')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPCo7NsxR8FJ",
        "outputId": "cdc79761-315b-4878-dd11-f860fa1239af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 14055 images belonging to 1 classes.\n",
            "Found 3513 images belonging to 1 classes.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "\n",
        "train_data = datagen.flow_from_directory(\n",
        "    '/content/chest-xray-pneumonia',  # Change this to the path where your dataset is\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='binary',\n",
        "    subset='training')\n",
        "\n",
        "val_data = datagen.flow_from_directory(\n",
        "    '/content/chest-xray-pneumonia',  # Same path\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='binary',\n",
        "    subset='validation')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkArUlMSpVn1"
      },
      "source": [
        "Build the model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "yLwPefrwpYXW",
        "outputId": "d617e487-b08f-432f-d016-01cd2bc4ce9a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ resnet50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)          │      <span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_average_pooling2d             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,098,176</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,025</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ resnet50 (\u001b[38;5;33mFunctional\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m2048\u001b[0m)          │      \u001b[38;5;34m23,587,712\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_average_pooling2d             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                │       \u001b[38;5;34m2,098,176\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │           \u001b[38;5;34m1,025\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,686,913</span> (97.99 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m25,686,913\u001b[0m (97.99 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,099,201</span> (8.01 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,099,201\u001b[0m (8.01 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> (89.98 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m23,587,712\u001b[0m (89.98 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "\n",
        "\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Freeze the base model layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Build the model\n",
        "model = Sequential([\n",
        "    base_model,\n",
        "    GlobalAveragePooling2D(),\n",
        "    Dense(1024, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')  # Binary classification\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YX1QB6aAPO9e"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "def check_images(directory):\n",
        "    for root, _, files in os.walk(directory):\n",
        "        for file in files:\n",
        "            try:\n",
        "                img_path = os.path.join(root, file)\n",
        "                img = Image.open(img_path)\n",
        "                img.verify()\n",
        "            except Exception as e:\n",
        "                print(f\"Corrupt or invalid image found: {img_path}, Error: {e}\")\n",
        "                os.remove(img_path)\n",
        "\n",
        "# Check both training and validation folders\n",
        "check_images('/path/to/your/data/train')\n",
        "check_images('/path/to/your/data/val')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jk_BI1mTOnpc"
      },
      "source": [
        "train model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6E5PSXwbR0Uc",
        "outputId": "2ac0b512-4dcd-4c67-dce0-7986c5ea9ad8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 4173 images belonging to 2 classes.\n",
            "Found 1043 images belonging to 2 classes.\n",
            "Found 624 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Data augmentation and rescaling\n",
        "datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
        "\n",
        "# Training data\n",
        "train_data = datagen.flow_from_directory(\n",
        "    '/content/chest-xray-pneumonia/chest_xray/train',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='binary',\n",
        "    subset='training',\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "# Validation data\n",
        "val_data = datagen.flow_from_directory(\n",
        "    '/content/chest-xray-pneumonia/chest_xray/train',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='binary',\n",
        "    subset='validation',\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "# Test data\n",
        "test_data = datagen.flow_from_directory(\n",
        "    '/content/chest-xray-pneumonia/chest_xray/test',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='binary',\n",
        "    shuffle=False\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oL8no1j3Op3w",
        "outputId": "4b949e85-3e51-4f1d-d1ad-a4ed58a06271"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m905s\u001b[0m 7s/step - accuracy: 0.7235 - loss: 0.6375 - val_accuracy: 0.7795 - val_loss: 0.4059\n",
            "Epoch 2/10\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m912s\u001b[0m 7s/step - accuracy: 0.8041 - loss: 0.4111 - val_accuracy: 0.7881 - val_loss: 0.3913\n",
            "Epoch 3/10\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m898s\u001b[0m 7s/step - accuracy: 0.8374 - loss: 0.3604 - val_accuracy: 0.8226 - val_loss: 0.3391\n",
            "Epoch 4/10\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m922s\u001b[0m 7s/step - accuracy: 0.8328 - loss: 0.3630 - val_accuracy: 0.8581 - val_loss: 0.3294\n",
            "Epoch 5/10\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m923s\u001b[0m 7s/step - accuracy: 0.8436 - loss: 0.3431 - val_accuracy: 0.8495 - val_loss: 0.2963\n",
            "Epoch 6/10\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m939s\u001b[0m 7s/step - accuracy: 0.8572 - loss: 0.3101 - val_accuracy: 0.8754 - val_loss: 0.2742\n",
            "Epoch 7/10\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m884s\u001b[0m 7s/step - accuracy: 0.8610 - loss: 0.3058 - val_accuracy: 0.8341 - val_loss: 0.3899\n",
            "Epoch 8/10\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m918s\u001b[0m 7s/step - accuracy: 0.8838 - loss: 0.2789 - val_accuracy: 0.8849 - val_loss: 0.2506\n",
            "Epoch 9/10\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m882s\u001b[0m 7s/step - accuracy: 0.8889 - loss: 0.2698 - val_accuracy: 0.9041 - val_loss: 0.2332\n",
            "Epoch 10/10\n",
            "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m882s\u001b[0m 7s/step - accuracy: 0.8824 - loss: 0.2743 - val_accuracy: 0.8562 - val_loss: 0.2715\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "    train_data,\n",
        "    epochs=10,\n",
        "    validation_data=val_data\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5DxSWpsgn1O"
      },
      "source": [
        "Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7pPNhVDgraN",
        "outputId": "db92ecee-9e36-4a0f-c692-0c3f7c638a45"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 5s/step - accuracy: 0.8611 - loss: 0.2657\n",
            "Test Accuracy: 85.62%\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_acc = model.evaluate(val_data)\n",
        "print(f\"Test Accuracy: {test_acc*100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7X3XcVwrgw-g"
      },
      "outputs": [],
      "source": [
        "model.save('pneumonia_model.h5')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQCtIrvX5BDW",
        "outputId": "462750aa-ce0c-47f3-b91f-e83fcb963343"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Load the saved model\n",
        "model = load_model(\"pneumonia_model.h5\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VKG6WXIIDZ2T",
        "outputId": "fcd594ca-d199-4421-fbea-8c6541c25c7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved artifact at '/tmp/tmptkchpsgi'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name='input_layer_1')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 1), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  137874101237520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137874101239632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137874101239440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137874101238864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137874101238096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137874101238672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137874101239248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137874101238288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873899126864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873899127248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873899127824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873899127056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873899127632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873899130128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873899130512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873899129744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873899129552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873899130320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873899132624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873899133200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873899131280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873899132432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873899133584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873899131664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873899132816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873899133392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873899134736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873899135120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873899133968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873899134352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873899136656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873899136848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873899137232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873899136272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873899128208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873899137040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873899138768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873899138960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873899139344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873899138384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873899130896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873899139152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873899140112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873899141264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873899141648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873899139728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873899140496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873899141456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873899140880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873899142416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873863656272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873863655504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873899142800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873863655696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873863657040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873863658192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873863658576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873863656656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873863657424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873863658384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873863659344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873863660496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873863660880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873863658960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873863659728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873863660688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873863661648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873863662800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873863663184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873863661264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873863662032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873863662992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873863663952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873863665104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873863665488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873863663568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873863664336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873863665296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873863667600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873863668176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873863666256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873863667408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873863668560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873863666640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873863667792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873863668368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873863669712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873863670096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873863668944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873863669328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873863670864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873863670480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873863869456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873863869072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873863671248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873863868880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873863869840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873863870992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873863871376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873863869264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873863870224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873863871184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873863872144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873863873296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873863873680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873863871760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873863872528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873863873488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873863874448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873863875600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873863875984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873863874064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873863874832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873863875792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873863876752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873863877904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873863878288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873863876368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873863877136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873863878096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873863879056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873863880208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873863880592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873863878672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873863879440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873863880400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873863881360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873863882512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873863882896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873863880976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873863881744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873863882704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873863883664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873863883280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864032336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864033104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873863868496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873863884048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864033488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864034640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864035024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864032528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864033872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864034832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864035792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864036944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864037328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864035408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864036176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864037136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864038096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864039248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864040208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864041168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864040400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864041552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864038864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864038480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864040976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864043472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864040016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864040784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864032720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864039824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864043856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864044240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864039440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864043280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864045008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864046160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864046544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864044624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864045392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864046352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864047312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864046928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864245712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864246288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864042512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864048464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864246096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864247440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864247824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864245904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864246672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864247632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864248592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864249744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864250128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864248208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864248976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864249936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864250896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864252048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864252432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864250512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864251280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864252240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864253200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864254352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864254736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864252816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864253584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864254544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864255504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864256656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864257040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864255120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864255888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864256848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864257808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864258960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864259344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864257424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864258192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864259152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864260112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864261072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864261264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864458896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864245328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864261456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864459088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864460240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864460624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864458512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864459472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864460432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864461392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864462544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864462928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864461008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864461776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864462736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864463696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864464848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864465232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864463312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864464080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864465040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864466000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864467152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864467536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864465616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864466384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864467344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864468304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864469456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864469840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864467920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864468688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864469648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864470608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864471760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864472144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864470224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864470992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864471952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864472912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864474064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864458704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873862525392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864473296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873864474256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873862525584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873862526736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873862527120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873862525968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873862525776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873862526928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873862529232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873862529808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873862527888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873862529040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873862530192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873862528272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873862529424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873862530000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873862531344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873862531728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873862530576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873862530960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873862532496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873862533648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873862534032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873862532112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873862532880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873862533840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873862534800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873862535952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873862536336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873862534416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873862535184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873862536144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873862537104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873862538256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873862538640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873862536720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873862537488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873862538448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873862539408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873862540560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873862525008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873862540944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873862539792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873862540752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873862672848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873862674000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873862674384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873862673616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873862673424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873862674192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873862675152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873862676304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873862676688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873862674768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873862675536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873862676496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873862673232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873862679184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873862678800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137873862679952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
          ]
        }
      ],
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "with open('pneumonia_model.tflite', 'wb') as f:\n",
        "    f.write(tflite_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rT1Aq280Di7l"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Load the TensorFlow Lite model\n",
        "interpreter = tf.lite.Interpreter(model_path='pneumonia_model.tflite')\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# Get input and output details\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "def predict_pneumonia(image):\n",
        "    # Preprocess the image\n",
        "    image = np.array(image)\n",
        "    image = cv2.resize(image, (224, 224))\n",
        "    image = image.astype('float32') / 255.0\n",
        "    image = np.expand_dims(image, axis=0)\n",
        "\n",
        "    # Set input tensor\n",
        "    interpreter.set_tensor(input_details[0]['index'], image)\n",
        "\n",
        "    # Run inference\n",
        "    interpreter.invoke()\n",
        "\n",
        "    # Get output tensor\n",
        "    prediction = interpreter.get_tensor(output_details[0]['index'])[0][0]\n",
        "    confidence = float(prediction)\n",
        "\n",
        "    return \"Pneumonia Positive 🚨\" if confidence > 0.5 else \"Normal ✅\", confidence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "18C3UjYsvFOb",
        "outputId": "11592d15-82f5-4ad0-8401-0a42f59aa3fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-01-29 21:54:22.452337: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2025-01-29 21:54:22.477094: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2025-01-29 21:54:22.484213: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-01-29 21:54:23.935576: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "/usr/local/lib/python3.11/dist-packages/gradio/interface.py:403: UserWarning: The `allow_flagging` parameter in `Interface` is deprecated.Use `flagging_mode` instead.\n",
            "  warnings.warn(\n",
            "* Running on local URL:  http://127.0.0.1:7861\n",
            "* Running on public URL: https://4b285adcebe59e3d15.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/queueing.py\", line 625, in process_events\n",
            "    response = await route_utils.call_process_api(\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/route_utils.py\", line 322, in call_process_api\n",
            "    output = await app.get_blocks().process_api(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 2044, in process_api\n",
            "    result = await self.call_function(\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 1591, in call_function\n",
            "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/to_thread.py\", line 33, in run_sync\n",
            "    return await get_asynclib().run_sync_in_worker_thread(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
            "    result = context.run(func, *args)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/utils.py\", line 883, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/app.py\", line 12, in predict_pneumonia\n",
            "    image = cv2.resize(image, (224, 224))\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "cv2.error: OpenCV(4.10.0) :-1: error: (-5:Bad argument) in function 'resize'\n",
            "> Overload resolution failed:\n",
            ">  - src data type = object is not supported\n",
            ">  - Expected Ptr<cv::UMat> for argument 'src'\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n"
          ]
        }
      ],
      "source": [
        "!python /content/app.py\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPEa5jNjPntjABg/2MlKxOR",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}